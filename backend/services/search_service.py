# å¼•ç”¨æˆ‘ä»¬åœ¨ graph_client.py ä¸­åˆå§‹åŒ–çš„å…¨å±€å®ä¾‹
from typing import Dict, Any, List

from backend.core.graph_client import graphiti_app, vector_store


class SearchService:
    """
    æœç´¢æœåŠ¡ï¼šè´Ÿè´£æ··åˆæ£€ç´¢ï¼ˆå‘é‡å¬å› + å›¾è°±è¡¥å…¨ï¼‰
    """

    @staticmethod
    async def hybrid_search(query: str, limit: int = 5) -> Dict[str, Any]:
        print(f"ğŸ” [Search] ç”¨æˆ·æŸ¥è¯¢: {query}")

        # ==========================================
        # 1. å‘é‡å¬å› (Semantic Search) -> è·å– ID
        # ==========================================
        # è¿™ä¸€æ­¥ç”¨ LangChain çš„ vector_storeï¼Œå› ä¸ºå®ƒå°è£…å¥½äº† Embedding è¿‡ç¨‹
        try:
            # è¿”å›æ ¼å¼: List[(Document, score)]
            vector_results = await vector_store.asimilarity_search_with_score(query, k=limit)
        except Exception as e:
            print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            return {"error": "Vector search failed"}

        if not vector_results:
            return {"results": [], "message": "No vector matches found"}

        # æå–å…³é”®ä¿¡æ¯ï¼šID å’Œ åˆ†æ•°
        candidate_ids = []
        candidates_map = {}  # ç”¨ map æ–¹ä¾¿åç»­åˆå¹¶

        for doc, score in vector_results:
            # è¿™é‡Œçš„ metadata['product_code'] æ˜¯æˆ‘ä»¬åœ¨ IngestionService é‡Œå­˜è¿›å»çš„é”šç‚¹
            code = doc.metadata.get("product_code")
            if code:
                # è¿‡æ»¤é‡å¤ ID
                if code not in candidates_map:
                    candidate_ids.append(code)
                    candidates_map[code] = {
                        "code": code,
                        "score": score,
                        "semantic_text": doc.page_content,
                        "metadata": doc.metadata,
                        "graph_data": {}  # å ä½
                    }

        print(f"âœ… å‘é‡å¬å› ID: {candidate_ids}")

        # ==========================================
        # 2. å›¾è°±è¡¥å…¨ (Graph Lookup) -> è·å–ç»“æ„åŒ–è¯¦æƒ…
        # ==========================================
        # è¿™é‡Œä¸ä½¿ç”¨ LLMï¼Œè€Œæ˜¯ç›´æ¥æ‰§è¡Œé«˜æ•ˆçš„ Cypher
        # ç›®çš„ï¼šæŸ¥å‡ºè¿™äº› ID å¯¹åº”çš„ Product èŠ‚ç‚¹ï¼Œä»¥åŠå®ƒæŒ‚è½½çš„æ‰€æœ‰ Attribute

        cypher_query = """
        MATCH (p:Product)
        WHERE p.name IN $codes  // ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ï¼Œå®‰å…¨ä¸”å¿«

        // 1. æŠ“å–äº§å“è‡ªèº«å±æ€§ (ä» EpisodeBody è§£æå‡ºæ¥çš„)
        // å‡è®¾ attributes å­˜åœ¨èŠ‚ç‚¹å±æ€§é‡Œï¼Œæˆ–è€…æˆ‘ä»¬åªæŸ¥å…³è”è¾¹

        // 2. æŠ“å–å…³è”çš„å±æ€§èŠ‚ç‚¹ (HAS_ATTR è¾¹)
        OPTIONAL MATCH (p)-[:HAS_ATTR]->(attr:ProductAttr)

        RETURN p.name as code, 
               p.group_id as group_id,
               // èšåˆè¯¥äº§å“çš„æ‰€æœ‰å±æ€§ä¸ºåˆ—è¡¨
               collect({field: attr.field, value: attr.value}) as attributes
        """

        try:
            # ä½¿ç”¨ graphiti_app.driver ç›´æ¥æ‰§è¡Œï¼Œç»•è¿‡ LangChain Chain
            # async_session æ˜¯ Neo4j å®˜æ–¹é©±åŠ¨çš„å¼‚æ­¥ä¼šè¯
            async with graphiti_app.driver.session() as session:
                result = await session.run(cypher_query, codes=candidate_ids)
                records: List[Dict[str, Any]] = await result.data()

            # å°†å›¾è°±æŸ¥åˆ°çš„ç»“æœå›å¡«åˆ° map ä¸­
            for record in records:
                # ç¡®ä¿ record æ˜¯ dict[str, Any] ç±»å‹
                record_dict: Dict[str, Any] = dict(record) if isinstance(record, dict) else record
                code = record_dict["code"]
                if code in candidates_map:
                    candidates_map[code]["graph_data"] = {
                        "group_id": record_dict["group_id"],
                        "attributes": record_dict["attributes"]
                    }

            print(f"âœ… å›¾è°±è¡¥å…¨å®Œæˆï¼Œå…± {len(records)} æ¡å…³è”æ•°æ®")

        except Exception as e:
            print(f"âš ï¸ å›¾è°±æŸ¥è¯¢å¤±è´¥ (é™çº§ä¸ºä»…è¿”å›å‘é‡ç»“æœ): {e}")

        # ==========================================
        # 3. ç»“æœæ’åºä¸è¿”å›
        # ==========================================
        # å°† map è½¬å› listï¼Œå¹¶æŒ‰åˆ†æ•°æ’åº
        final_results = sorted(
            candidates_map.values(),
            key=lambda x: x["score"],
            reverse=True
        )

        return {
            "query": query,
            "total_candidates": len(final_results),
            "results": final_results
        }
