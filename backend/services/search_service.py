from typing import Dict, Any, List
import requests
from langchain_core.documents import Document

from backend.core.graph_client import graphiti_app, QDRANT_URL, langchain_embeddings


class SearchService:
    """
    æœç´¢æœåŠ¡ï¼šè´Ÿè´£æ··åˆæ£€ç´¢ï¼ˆå‘é‡å¬å› + å›¾è°±è¡¥å…¨ï¼‰
    """

    @staticmethod
    async def hybrid_search(query: str, limit: int = 5) -> Dict[str, Any]:
        print(f"ğŸ” [Search] ç”¨æˆ·æŸ¥è¯¢: {query}")

        try:
            embed = langchain_embeddings.embed_query(query)
            resp = requests.post(
                f"{QDRANT_URL}/collections/multimodal_knowledge/points/search",
                json={
                    "vector": embed,
                    "limit": limit * 3,
                    "with_payload": True,
                },
                timeout=10,
            )
            resp.raise_for_status()
            data = resp.json()
            points = data.get("result", [])
            vector_results: List[tuple[Document, float]] = []
            for p in points:
                payload = p.get("payload") or {}
                page_content = payload.get("page_content", "")
                metadata = payload.get("metadata", {})
                doc = Document(page_content=page_content, metadata=metadata)
                score = p.get("score", 0.0)
                vector_results.append((doc, score))
        except Exception as e:
            print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            return {"error": "Vector search failed"}

        if not vector_results:
            return {"results": [], "message": "No vector matches found"}

        # æå–å…³é”®ä¿¡æ¯ï¼šID å’Œ åˆ†æ•°
        candidate_ids = []
        candidates_map = {}  # ç”¨ map æ–¹ä¾¿åç»­åˆå¹¶

        for doc, score in vector_results:
            meta = doc.metadata
            if meta.get("entity_label") == "Product":
                code = meta.get("entity_id")
                if code and code not in candidates_map:
                    candidate_ids.append(code)
                    candidates_map[code] = {
                        "code": code,
                        "score": score,
                        "semantic_text": doc.page_content,
                        "metadata": meta,
                        "graph_data": {}
                    }

        print(f"âœ… å‘é‡å¬å› ID: {candidate_ids}")

        # ==========================================
        # 2. å›¾è°±è¡¥å…¨ (Graph Lookup) -> è·å–ç»“æ„åŒ–è¯¦æƒ…
        # ==========================================
        # è¿™é‡Œä¸ä½¿ç”¨ LLMï¼Œè€Œæ˜¯ç›´æ¥æ‰§è¡Œé«˜æ•ˆçš„ Cypher
        # ç›®çš„ï¼šæŸ¥å‡ºè¿™äº› ID å¯¹åº”çš„ Product èŠ‚ç‚¹ï¼Œä»¥åŠå®ƒæŒ‚è½½çš„æ‰€æœ‰ Attribute

        cypher_query = """
        MATCH (p:Product)
        WHERE p.code IN $codes
        RETURN p
        """

        try:
            async with graphiti_app.driver.session() as session:
                result = await session.run(cypher_query, codes=candidate_ids)
                records: List[Dict[str, Any]] = await result.data()

            for record in records:
                record_dict: Dict[str, Any] = dict(record) if isinstance(record, dict) else record
                node = record_dict.get("p") or {}
                code = node.get("code")
                if code and code in candidates_map:
                    candidates_map[code]["graph_data"] = node

            print(f"âœ… å›¾è°±è¡¥å…¨å®Œæˆï¼Œå…± {len(records)} æ¡å…³è”æ•°æ®")

        except Exception as e:
            print(f"âš ï¸ å›¾è°±æŸ¥è¯¢å¤±è´¥ (é™çº§ä¸ºä»…è¿”å›å‘é‡ç»“æœ): {e}")

        # ==========================================
        # 3. ç»“æœæ’åºä¸è¿”å›
        # ==========================================
        # å°† map è½¬å› listï¼Œå¹¶æŒ‰åˆ†æ•°æ’åº
        final_results = sorted(
            candidates_map.values(),
            key=lambda x: x["score"],
            reverse=True
        )

        return {
            "query": query,
            "total_candidates": len(final_results),
            "results": final_results
        }
