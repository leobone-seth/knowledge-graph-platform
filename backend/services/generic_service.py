import asyncio
import json
from typing import List, Dict, Any, Optional

import requests
from langchain_core.documents import Document

from backend.core.graph_client import (
    graphiti_app,
    vector_store,
    QDRANT_URL,
    langchain_embeddings,
)


class GenericEntityService:
    """
    é€šç”¨å®žä½“æœåŠ¡ (Generic Entity Service)

    èŒè´£ï¼š
    1. æä¾›å¯¹ä»»æ„å®žä½“çš„ å¢ž(Ingest)ã€æŸ¥(Search)ã€æ”¹(Update) èƒ½åŠ›ã€‚
    2. ç»´æŠ¤ Graph (Neo4j) ä¸Ž Vector (Qdrant) çš„æ•°æ®ä¸€è‡´æ€§ã€‚
    3. æ”¯æŒè¯»å†™åˆ†ç¦»ç­–ç•¥ï¼šå¤§å­—æ®µåªå­˜å‘é‡åº“ï¼Œä¸å­˜å›¾æ•°æ®åº“ã€‚
    """

    RULE_LINK_PRESETS: Dict[str, Dict[str, Any]] = {
        "standard_to_product": {
            "source_label": "StandardDocument",
            "source_id_field": "standard_code",
            "target_label": "Product",
            "target_id_field": "code",
            "rel_type": "APPLIES_TO",
            "source_list_fields": ["tags"],
            "source_text_fields": ["title", "summary"],
            "target_text_fields": ["elem", "fun", "className", "series"],
            "mode": "contains_any",
        },
        "sensory_to_product": {
            "source_label": "Sensory",
            "source_id_field": "name",
            "target_label": "Product",
            "target_id_field": "code",
            "rel_type": "EVOKES",
            "source_list_fields": [],
            "source_text_fields": ["name"],
            "target_text_fields": ["fun"],
            "mode": "contains_any",
        },
        "season_to_product": {
            "source_label": "Season",
            "source_id_field": "name",
            "target_label": "Product",
            "target_id_field": "code",
            "rel_type": "SUITS_FOR",
            "source_list_fields": [],
            "source_text_fields": ["name"],
            "target_text_fields": ["season_marking"],
            "mode": "equals_any",
        },
    }

    @staticmethod
    def _validate_cypher_identifier(value: str) -> str:
        if not value or not isinstance(value, str):
            raise ValueError("Invalid identifier")
        ok = all((c.isalnum() or c == "_") for c in value)
        if not ok:
            raise ValueError(f"Invalid identifier: {value}")
        return value

    @staticmethod
    async def link_entities_by_rules(
            source_label: str,
            source_id_field: str,
            target_label: str,
            target_id_field: str,
            source_list_fields: Optional[List[str]] = None,
            source_text_fields: Optional[List[str]] = None,
            target_text_fields: Optional[List[str]] = None,
            rel_type: str = "RELATED_TO",
            mode: str = "contains_any",
    ) -> int:
        source_list_fields = source_list_fields or []
        source_text_fields = source_text_fields or []
        target_text_fields = target_text_fields or []

        src_lbl = GenericEntityService._validate_cypher_identifier(source_label)
        tgt_lbl = GenericEntityService._validate_cypher_identifier(target_label)
        src_id = GenericEntityService._validate_cypher_identifier(source_id_field)
        tgt_id = GenericEntityService._validate_cypher_identifier(target_id_field)
        rel = GenericEntityService._validate_cypher_identifier(rel_type)

        for f in source_list_fields + source_text_fields + target_text_fields:
            GenericEntityService._validate_cypher_identifier(f)

        if mode not in {"contains_any", "equals_any"}:
            raise ValueError("Invalid mode")

        conditions: List[str] = []

        for sf in source_list_fields:
            per_target = []
            for tf in target_text_fields:
                if mode == "equals_any":
                    per_target.append(
                        f"coalesce(trim(toString(p.{tf})), '') = coalesce(trim(toString(k)), '')"
                    )
                else:
                    per_target.append(f"coalesce(toString(p.{tf}), '') CONTAINS toString(k)")
            if per_target:
                conditions.append(
                    f"ANY(k IN coalesce(s.{sf}, []) WHERE coalesce(trim(toString(k)), '') <> '' AND ({' OR '.join(per_target)}))"
                )

        for sf in source_text_fields:
            for tf in target_text_fields:
                if mode == "equals_any":
                    conditions.append(
                        f"(coalesce(trim(toString(s.{sf})), '') <> '' AND "
                        f"coalesce(trim(toString(p.{tf})), '') <> '' AND "
                        f"coalesce(trim(toString(p.{tf})), '') = coalesce(trim(toString(s.{sf})), ''))"
                    )
                else:
                    conditions.append(
                        f"(coalesce(trim(toString(s.{sf})), '') <> '' AND "
                        f"coalesce(trim(toString(p.{tf})), '') <> '' AND "
                        f"coalesce(toString(p.{tf}), '') CONTAINS coalesce(toString(s.{sf}), ''))"
                    )

        if not conditions:
            return 0

        cypher = f"""
        MATCH (s:{src_lbl})
        MATCH (p:{tgt_lbl})
        WHERE ({' OR '.join(conditions)})
        MERGE (s)-[:{rel}]->(p)
        RETURN count(*) as edges_created
        """

        async with graphiti_app.driver.session() as session:
            result = await session.run(cypher)
            record = await result.single()
            if record and "edges_created" in record:
                return int(record["edges_created"])
            return 0

    @staticmethod
    async def run_rule_preset(preset_name: str) -> Dict[str, Any]:
        preset = GenericEntityService.RULE_LINK_PRESETS.get(preset_name)
        if not preset:
            return {"status": "error", "message": "Preset not found"}

        edges = await GenericEntityService.link_entities_by_rules(**preset)
        return {"status": "success", "preset": preset_name, "edges_created": edges}

    # ==========================================
    # 1. é€šç”¨å†™å…¥ (Generic Write / Ingest)
    # ==========================================
    @staticmethod
    async def ingest_entities(
            data_list: List[Dict[str, Any]],
            label: str,  # e.g., "Product", "User", "StandardDocument"
            id_field: str,  # e.g., "code", "user_id", "standard_code"
            vector_template: str,  # e.g., "æ ‡é¢˜: {title}, æ‘˜è¦: {summary}"
            graph_exclude_fields: Optional[List[str]] = None,  # ä¸éœ€è¦å­˜å…¥ Neo4j çš„å¤§å­—æ®µåˆ—è¡¨
            group_id: str = "default",
            concurrency: int = 5
    ):
        """
        é€šç”¨çš„æ‰¹é‡å…¥åº“æ–¹æ³•

        Args:
            data_list: å¾…å†™å…¥çš„æ•°æ®å­—å…¸åˆ—è¡¨
            label: Neo4j ä¸­çš„èŠ‚ç‚¹æ ‡ç­¾ (Label)
            id_field: æ•°æ®ä¸­ä½œä¸ºå”¯ä¸€ä¸»é”®çš„å­—æ®µå
            vector_template: ç”¨äºŽç”Ÿæˆå‘é‡æ–‡æœ¬çš„å­—ç¬¦ä¸²æ¨¡ç‰ˆ
            graph_exclude_fields: æŒ‡å®šå“ªäº›å­—æ®µä¸éœ€è¦å†™å…¥ Neo4j (ä¾‹å¦‚è¶…é•¿çš„æ­£æ–‡)
            group_id: æ•°æ®åˆ†ç»„ ID
            concurrency: å¹¶å‘å†™å…¥çš„çº¿ç¨‹/ä»»åŠ¡æ•°
        """
        if graph_exclude_fields is None:
            graph_exclude_fields = []

        print(f"ðŸš€ [Generic] å¼€å§‹å¯¼å…¥ {label}ï¼Œå…± {len(data_list)} æ¡ï¼Œå¹¶å‘åº¦: {concurrency}")

        # ä½¿ç”¨ä¿¡å·é‡æŽ§åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(concurrency)

        async def _process_single(item: Dict[str, Any]):
            async with semaphore:
                try:
                    # 1. èŽ·å–å¹¶æ ¡éªŒä¸»é”®
                    unique_id = item.get(id_field)
                    if not unique_id:
                        # å°è¯•è½¬ä¸ºå­—ç¬¦ä¸²æŸ¥æ‰¾ï¼Œæˆ–è€…è·³è¿‡
                        print(f"âš ï¸ è·³è¿‡æ— ä¸»é”®æ•°æ®: {str(item)[:50]}...")
                        return

                    # === Step A: å†™å…¥ Graph (Neo4j) ===
                    # å‡†å¤‡å†™å…¥ Neo4j çš„å±žæ€§ï¼šè¿‡æ»¤æŽ‰å¤§å­—æ®µ
                    graph_props = item.copy()
                    for field in graph_exclude_fields:
                        if field in graph_props:
                            del graph_props[field]

                    # åŠ¨æ€å†™å…¥èŠ‚ç‚¹
                    await GenericEntityService._write_node_to_neo4j(label, id_field, unique_id, graph_props)

                    # === Step B: å†™å…¥ Vector Store (Qdrant) ===
                    # åŠ¨æ€ç”Ÿæˆå‘é‡æ–‡æœ¬ (ä½¿ç”¨åŽŸå§‹å®Œæ•´æ•°æ® item)
                    try:
                        # å¤„ç† None å€¼ï¼Œé˜²æ­¢ format æŠ¥é”™
                        safe_data = {k: v if v is not None else "" for k, v in item.items()}
                        text_content = vector_template.format(**safe_data)
                    except KeyError as e:
                        print(f"âš ï¸ å‘é‡æ¨¡ç‰ˆåŒ¹é…å¤±è´¥ ({e})ï¼Œé™çº§ä¸º JSON æ–‡æœ¬")
                        text_content = json.dumps(item, ensure_ascii=False)
                    except Exception as e:
                        print(f"âš ï¸ å‘é‡ç”ŸæˆæœªçŸ¥é”™è¯¯: {e}")
                        text_content = str(item)

                    # æž„å»º Document å¯¹è±¡
                    doc = Document(
                        page_content=text_content,
                        metadata={
                            "entity_id": str(unique_id),  # ç»Ÿä¸€å­˜å‚¨ä¸ºå­—ç¬¦ä¸² ID
                            "entity_label": label,  # ç”¨äºŽè¿‡æ»¤
                            "original_id_field": id_field,  # ç”¨äºŽå›žæŸ¥
                            "group_id": group_id
                        }
                    )

                    # å¼‚æ­¥å†™å…¥å‘é‡åº“
                    await vector_store.aadd_documents([doc])

                except Exception as e:
                    print(f"âŒ å¤„ç† {unique_id} å¤±è´¥: {e}")

        # åˆ›å»ºå¹¶æ‰§è¡Œä»»åŠ¡
        tasks = [_process_single(d) for d in data_list]
        if tasks:
            await asyncio.gather(*tasks)

        print(f"âœ… {label} å¯¼å…¥æµç¨‹ç»“æŸ")

    @staticmethod
    async def _write_node_to_neo4j(label: str, id_field: str, unique_id: Any, properties: Dict):
        """
        å†…éƒ¨æ–¹æ³•ï¼šåŠ¨æ€ç”Ÿæˆ MERGE è¯­å¥å¹¶å†™å…¥ Neo4j
        [ä¿®æ”¹ç‰ˆ] è‡ªåŠ¨å°†å­—å…¸æˆ–å¤æ‚åˆ—è¡¨åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼Œé˜²æ­¢ Neo4j æŠ¥é”™
        """
        clean_props = {}

        for k, v in properties.items():
            # 1. è·³è¿‡ None (Neo4j ä¸å­˜ Null)
            if v is None:
                continue

            # 2. å¤„ç†å­—å…¸ (Dict) -> è½¬ JSON å­—ç¬¦ä¸²
            # è§£å†³ extra_metadata æŠ¥é”™çš„æ ¸å¿ƒé€»è¾‘
            if isinstance(v, dict):
                try:
                    clean_props[k] = json.dumps(v, ensure_ascii=False)
                except Exception:
                    clean_props[k] = str(v)

            # 3. å¤„ç†åˆ—è¡¨ (List)
            elif isinstance(v, list):
                if len(v) > 0:
                    # å¦‚æžœåˆ—è¡¨é‡ŒåŒ…å«å­—å…¸ (e.g. List[Dict])ï¼ŒNeo4j ä¹Ÿä¸æ”¯æŒ -> è½¬ JSON å­—ç¬¦ä¸²
                    if isinstance(v[0], (dict, list)):
                        try:
                            clean_props[k] = json.dumps(v, ensure_ascii=False)
                        except Exception:
                            clean_props[k] = str(v)
                    else:
                        # å¦‚æžœæ˜¯ List[str] æˆ– List[int]ï¼ŒNeo4j æ”¯æŒ -> ç›´æŽ¥ä¿ç•™
                        clean_props[k] = v
                else:
                    # ç©ºåˆ—è¡¨å¯ä»¥é€‰æ‹©ä¸å­˜ï¼Œæˆ–è€…å­˜ä¸ºç©ºæ•°ç»„
                    clean_props[k] = v

            # 4. å…¶ä»–åŸºæœ¬ç±»åž‹ (int, str, float) -> ç›´æŽ¥ä¿ç•™
            else:
                clean_props[k] = v

        # åŠ¨æ€æž„é€  Cypher
        query = f"""
            MERGE (n:{label} {{ {id_field}: $uid }})
            SET n += $props, n.last_updated = datetime()
            """

        # ä½¿ç”¨ graphiti_app åº•å±‚çš„ driver
        async with graphiti_app.driver.session() as session:
            await session.run(query, uid=unique_id, props=clean_props)
    # ==========================================
    # 2. é€šç”¨æŸ¥è¯¢ (Generic Query / Search)
    # ==========================================
    @staticmethod
    async def generic_search(
            query: str,
            target_label: str,  # é™åˆ¶æœç´¢æŸç§ç±»åž‹
            limit: int = 5
    ) -> Dict[str, Any]:
        """
        é€šç”¨æ··åˆæ£€ç´¢ï¼šå‘é‡å¬å›ž + å›¾è°±å±žæ€§è¡¥å…¨
        """
        print(f"ðŸ”Ž [GenericSearch] æŸ¥ {target_label}: {query}")

        # === Step A: å‘é‡å¬å›ž ===
        try:
            embed = langchain_embeddings.embed_query(query)
            resp = requests.post(
                f"{QDRANT_URL}/collections/multimodal_knowledge/points/search",
                json={
                    "vector": embed,
                    "limit": limit * 3,
                    "with_payload": True,
                },
                timeout=10,
            )
            resp.raise_for_status()
            data = resp.json()
            points = data.get("result", [])
            vector_results = []
            for p in points:
                payload = p.get("payload") or {}
                page_content = payload.get("page_content", "")
                metadata = payload.get("metadata", {})
                doc = Document(page_content=page_content, metadata=metadata)
                score = p.get("score", 0.0)
                vector_results.append((doc, score))
        except Exception as e:
            print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            return {"results": [], "error": str(e)}

        candidates = []
        candidate_ids = []
        original_id_field = "id"  # é»˜è®¤å€¼

        for doc, score in vector_results:
            meta = doc.metadata
            # è¿‡æ»¤ï¼šåªä¿ç•™ç›®æ ‡ Label çš„æ•°æ®
            if meta.get("entity_label") == target_label:
                uid = meta.get("entity_id")
                # è®°å½•è¯¥å®žä½“åœ¨å›¾è°±ä¸­çš„ä¸»é”®å­—æ®µå (e.g., "code" or "standard_code")
                original_id_field = meta.get("original_id_field", "id")

                # åŽ»é‡
                if uid and uid not in candidate_ids:
                    candidates.append({
                        "id": uid,
                        "score": score,
                        "semantic_text": doc.page_content,  # å‘é‡åº“é‡Œçš„æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«å¤§å­—æ®µçš„æ‘˜è¦ï¼‰
                        "metadata": meta,
                        "graph_data": {}  # ç¨åŽå¡«å……
                    })
                    candidate_ids.append(uid)

            if len(candidate_ids) >= limit:
                break

        if not candidate_ids:
            return {"results": [], "message": "No matching entities found"}

        # === Step B: å›¾è°±è¡¥å…¨ (Graph Lookup) ===
        # ä½¿ç”¨ Cypher æ‰¹é‡æŸ¥å‡ºè¿™äº›å®žä½“çš„æœ€æ–°å±žæ€§
        cypher = f"""
        MATCH (n:{target_label})
        WHERE n.{original_id_field} IN $ids
        RETURN n
        """

        try:
            async with graphiti_app.driver.session() as session:
                result = await session.run(cypher, ids=candidate_ids)
                records = await result.data()

                # æž„å»º ID -> Node Props æ˜ å°„è¡¨
                graph_map = {}
                for r in records:
                    node = r['n']
                    # èŽ·å–è¯¥èŠ‚ç‚¹çš„ä¸»é”®å€¼
                    # æ³¨æ„ï¼šä»Ž Neo4j æ‹¿å›žæ¥çš„ node æ˜¯ dict ç»“æž„
                    node_id = node.get(original_id_field)
                    if node_id:
                        graph_map[str(node_id)] = node

                # å°†å›¾è°±æ•°æ®å›žå¡«åˆ°å€™é€‰åˆ—è¡¨ä¸­
                for cand in candidates:
                    cand_id = cand['id']
                    if cand_id in graph_map:
                        cand['graph_data'] = graph_map[cand_id]
                    else:
                        cand['graph_data'] = {"_status": "Not found in Graph (Sync delay?)"}

        except Exception as e:
            print(f"âš ï¸ å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
            # å³ä½¿å›¾è°±æŒ‚äº†ï¼Œä¹Ÿè¿”å›žå‘é‡ç»“æžœ

        return {"results": candidates}

    # ==========================================
    # 3. é€šç”¨ä¿®æ”¹ (Generic Modify / Update)
    # ==========================================
    @staticmethod
    async def update_entity(
            label: str,
            id_field: str,
            unique_id: str,
            update_data: Dict[str, Any]
    ) -> Optional[Dict]:
        """
        é€šç”¨æ›´æ–°å®žä½“å±žæ€§
        """
        # ç§»é™¤ None
        clean_props = {k: v for k, v in update_data.items() if v is not None}

        query = f"""
        MATCH (n:{label} {{ {id_field}: $uid }})
        SET n += $props, n.last_updated = datetime()
        RETURN n
        """

        try:
            async with graphiti_app.driver.session() as session:
                result = await session.run(query, uid=unique_id, props=clean_props)
                record = await result.single()
                if record:
                    return dict(record['n'])
                return None
        except Exception as e:
            print(f"âŒ æ›´æ–°å¤±è´¥: {e}")
            raise e

    @staticmethod
    async def delete_entity(
            label: str,
            id_field: str,
            unique_id: str
    ) -> int:
        query = f"""
        MATCH (n:{label} {{ {id_field}: $uid }})
        DETACH DELETE n
        RETURN count(*) as deleted_count
        """

        try:
            async with graphiti_app.driver.session() as session:
                result = await session.run(query, uid=unique_id)
                record = await result.single()
                if record:
                    return record["deleted_count"]
                return 0
        except Exception as e:
            print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
            raise e

    # ==========================================
    # 4. è¯­ä¹‰è‡ªåŠ¨å…³è” (Semantic Linking) [æ–°å¢ž]
    # ==========================================
    @staticmethod
    async def link_entities_by_semantic(
            source_label: str,  # æºèŠ‚ç‚¹ Labelï¼Œå¦‚ "StandardDocument"
            source_id_field: str,  # æºèŠ‚ç‚¹ä¸»é”®å­—æ®µï¼Œå¦‚ "standard_code"
            target_label: str,  # ç›®æ ‡èŠ‚ç‚¹ Labelï¼Œå¦‚ "Product"
            target_id_field: str,  # ç›®æ ‡èŠ‚ç‚¹ä¸»é”®å­—æ®µï¼Œå¦‚ "code"
            top_k: int = 10,  # æ¯ä¸ªæ–‡æ¡£å…³è”å¤šå°‘ä¸ªæœ€ç›¸ä¼¼çš„äº§å“
            score_threshold: float = 0.3  # ç›¸ä¼¼åº¦é˜ˆå€¼
    ):
        """
        [ä¿®å¤ç‰ˆ] è¯­ä¹‰å…³è”ï¼šä½¿ç”¨ HTTP æŽ¥å£ + Server-side Filterï¼Œé¿å…å®¢æˆ·ç«¯ç‰ˆæœ¬å…¼å®¹é—®é¢˜
        """
        print(f"ðŸ”— [Linking] å¼€å§‹å»ºç«‹å…³è”: ({source_label}) -> ({target_label})")

        # 1. ä»Ž Neo4j èŽ·å–æ‰€æœ‰æºèŠ‚ç‚¹
        fetch_query = f"MATCH (n:{source_label}) RETURN n.{source_id_field} as uid, n.title as text_content"

        async with graphiti_app.driver.session() as session:
            result = await session.run(fetch_query)
            records = await result.data()

        print(f"   å…±æ‰¾åˆ° {len(records)} ä¸ªæºå®žä½“å¾…å¤„ç†...")

        link_count = 0

        for rec in records:
            uid = rec["uid"]
            text = rec.get("text_content", "")

            if not uid or not text:
                continue

            try:
                # 2. ç”Ÿæˆå‘é‡ (ä½¿ç”¨ graph_client ä¸­åˆå§‹åŒ–çš„å…¨å±€ embedding æ¨¡åž‹)
                vector = langchain_embeddings.embed_query(text)

                # 3. æž„é€  Qdrant æœç´¢è¯·æ±‚ (å¸¦ Filter)
                # LangChain å°† metadata å­˜åœ¨ payload.metadata ä¸‹ï¼Œæ‰€ä»¥ key æ˜¯ "metadata.entity_label"
                search_payload = {
                    "vector": vector,
                    "limit": top_k,
                    "with_payload": True,
                    "score_threshold": score_threshold,  # Qdrant æ”¯æŒç›´æŽ¥ä¼ é˜ˆå€¼ï¼Œè¿‡æ»¤æŽ‰ä½Žåˆ†ç»“æžœ
                    "filter": {
                        "must": [
                            {
                                "key": "metadata.entity_label",
                                "match": {"value": target_label}
                            }
                        ]
                    }
                }

                # å‘é€ HTTP è¯·æ±‚ (å¤ç”¨ generic_search çš„é€»è¾‘)
                response = requests.post(
                    f"{QDRANT_URL}/collections/multimodal_knowledge/points/search",
                    json=search_payload,
                    timeout=60
                )
                response.raise_for_status()
                search_res = response.json()
                points = search_res.get("result", [])

                # 4. æå–ç›®æ ‡ ID å¹¶å»ºç«‹å…³è”
                targets_to_link = []
                resolved_target_id_field = target_id_field
                for point in points:
                    payload = point.get("payload", {})
                    metadata = payload.get("metadata", {})
                    resolved_target_id_field = metadata.get("original_id_field", resolved_target_id_field)
                    target_uid = metadata.get("entity_id")

                    if target_uid:
                        targets_to_link.append(target_uid)

                # 5. æ‰¹é‡å†™å…¥ Neo4j è¾¹
                if targets_to_link:
                    await GenericEntityService._create_edges_batch(
                        source_label, source_id_field, uid,
                        target_label, resolved_target_id_field, targets_to_link,
                        rel_type="APPLIES_TO"
                    )
                    link_count += len(targets_to_link)
                    print(f"   âœ… {uid} -> å…³è”äº† {len(targets_to_link)} ä¸ªäº§å“")

            except Exception as e:
                print(f"âŒ å¤„ç† {uid} å…³è”å¤±è´¥: {e}")

        print(f"âœ… å…³è”ä»»åŠ¡ç»“æŸï¼Œå…±åˆ›å»º {link_count} æ¡å…³ç³»ã€‚")

    @staticmethod
    async def _create_edges_batch(src_lbl, src_key, src_val, tgt_lbl, tgt_key, tgt_val_list, rel_type):
        """
        Neo4j æ‰¹é‡å»ºè¾¹ Cypher
        """
        cypher = f"""
        MATCH (s:{src_lbl} {{ {src_key}: $src_val }})
        MATCH (t:{tgt_lbl})
        WHERE t.{tgt_key} IN $tgt_vals
        MERGE (s)-[:{rel_type}]->(t)
        """
        async with graphiti_app.driver.session() as session:
            await session.run(cypher, src_val=src_val, tgt_vals=tgt_val_list)

    @staticmethod
    async def run_rule_based_linking():
        """
        åŸºäºŽæ ‡ç­¾çš„ç²¾ç¡®åŒ¹é…ï¼š
        å¦‚æžœ StandardDocument çš„ tags åŒ…å« 'é’ˆç»‡'ï¼Œ
        ä¸” Product çš„ attributes æˆ– series åŒ…å« 'é’ˆç»‡'ï¼Œåˆ™å»ºç«‹å…³è”ã€‚
        """
        cypher = """
            MATCH (s:StandardDocument), (p:Product)
            WHERE 
                // è§„åˆ™ï¼šæ ‡å‡†æ–‡æ¡£çš„æ ‡ç­¾ å‡ºçŽ°åœ¨ äº§å“çš„ç³»åˆ—åä¸­
                ANY(tag IN s.tags WHERE p.series CONTAINS tag)
                OR
                // è§„åˆ™ï¼šæˆ–è€…æ ‡é¢˜åŒ…å«äº§å“çš„ç±»åˆ«åç§°
                s.title CONTAINS p.className
            MERGE (s)-[:APPLIES_TO]->(p)
            RETURN count(*) as edges_created
            """
        async with graphiti_app.driver.session() as session:
            await session.run(cypher)
